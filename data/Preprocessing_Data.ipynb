{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_FIT: /teamspace/studios/this_studio/detecting_Sepsis/data/raw_CSV/train_fit.csv\n",
      "TRAIN_THRESH: /teamspace/studios/this_studio/detecting_Sepsis/data/raw_CSV/train_thresh.csv\n",
      "TEST: /teamspace/studios/this_studio/detecting_Sepsis/data/raw_CSV/test.csv\n",
      "LOW_OUT_DIR: /teamspace/studios/this_studio/detecting_Sepsis/data/Low_Preproc_NoFe_CSV\n",
      "HIGH_OUT_DIR: /teamspace/studios/this_studio/detecting_Sepsis/data/High_Preproc_NoFe_CSV\n"
     ]
    }
   ],
   "source": [
    "# Project root\n",
    "BASE_DIR = Path(\"/teamspace/studios/this_studio/detecting_Sepsis\")\n",
    "\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "RAW_CSV_DIR  = DATA_DIR / \"raw_CSV\"\n",
    "LOW_DIR      = DATA_DIR / \"Low_Preproc_NoFe_CSV\"\n",
    "HIGH_DIR     = DATA_DIR / \"High_Preproc_NoFe_CSV\"\n",
    "\n",
    "for d in [RAW_CSV_DIR, LOW_DIR, HIGH_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Raw inputs (your current files)\n",
    "TRAIN_FIT_CSV    = RAW_CSV_DIR / \"train_fit.csv\"\n",
    "TRAIN_THRESH_CSV = RAW_CSV_DIR / \"train_thresh.csv\"\n",
    "TEST_CSV         = RAW_CSV_DIR / \"test.csv\"\n",
    "\n",
    "# Column conventions\n",
    "PATIENT_COL = \"Patient_ID\"\n",
    "TIME_COL    = \"ICULOS\"\n",
    "LABEL_COL   = \"SepsisLabel\"\n",
    "\n",
    "# HIGH recency settings (match your loader)\n",
    "RECENCY_DECAY = 0.9\n",
    "NO_RECENCY_COLS = {\"Age\",\"Gender\",\"Unit1\",\"Unit2\",\"HospAdmTime\",\"ICULOS\"}\n",
    "\n",
    "print(\"TRAIN_FIT:\", TRAIN_FIT_CSV)\n",
    "print(\"TRAIN_THRESH:\", TRAIN_THRESH_CSV)\n",
    "print(\"TEST:\", TEST_CSV)\n",
    "print(\"LOW_OUT_DIR:\", LOW_DIR)\n",
    "print(\"HIGH_OUT_DIR:\", HIGH_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_csv(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    # Drop accidental index columns like Unnamed: 0\n",
    "    df = df.loc[:, ~df.columns.str.contains(r\"^Unnamed\")]\n",
    "    return df\n",
    "\n",
    "def get_feature_cols(df: pd.DataFrame) -> list[str]:\n",
    "    # Features are everything except patient/time/label\n",
    "    drop_cols = {PATIENT_COL, TIME_COL, LABEL_COL}\n",
    "    return [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "def recency_from_missing(missing_sub: np.ndarray, decay: float = 0.9) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    missing_sub: bool [T, F] where True = missing at time t\n",
    "    recency[t] = decay*recency[t-1], set to 1.0 when observed at t\n",
    "    \"\"\"\n",
    "    T, F = missing_sub.shape\n",
    "    rec = np.zeros((T, F), dtype=np.float32)\n",
    "    for t in range(T):\n",
    "        obs = ~missing_sub[t]\n",
    "        if t == 0:\n",
    "            rec[t, obs] = 1.0\n",
    "        else:\n",
    "            rec[t] = rec[t-1] * decay\n",
    "            rec[t, obs] = 1.0\n",
    "    return rec\n",
    "\n",
    "def make_low_preproc(df: pd.DataFrame, feature_cols: list[str]) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out = out.sort_values([PATIENT_COL, TIME_COL]).reset_index(drop=True)\n",
    "    out[feature_cols] = out[feature_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    out[feature_cols] = (\n",
    "        out.groupby(PATIENT_COL, sort=False)[feature_cols]\n",
    "           .ffill()\n",
    "           .fillna(0.0)\n",
    "    )\n",
    "    return out\n",
    "\n",
    "def make_high_preproc(df: pd.DataFrame, feature_cols: list[str], decay: float = 0.9) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out = out.sort_values([PATIENT_COL, TIME_COL]).reset_index(drop=True)\n",
    "\n",
    "    # numeric coercion (non-numeric -> NaN)\n",
    "    out[feature_cols] = out[feature_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # dynamic cols that get recency\n",
    "    dyn_cols = [c for c in feature_cols if c not in NO_RECENCY_COLS]\n",
    "    dyn_idx = [feature_cols.index(c) for c in dyn_cols]\n",
    "\n",
    "    recency_parts = []\n",
    "    for pid, g in out.groupby(PATIENT_COL, sort=False):\n",
    "        X_raw = g[feature_cols].to_numpy(dtype=np.float32, copy=True)\n",
    "        missing = np.isnan(X_raw)\n",
    "\n",
    "        if len(dyn_idx) == 0:\n",
    "            rec = np.zeros((len(g), 0), dtype=np.float32)\n",
    "        else:\n",
    "            rec = recency_from_missing(missing[:, dyn_idx], decay=decay)\n",
    "\n",
    "        rec_df = pd.DataFrame(\n",
    "            rec,\n",
    "            index=g.index,\n",
    "            columns=[f\"recency_{c}\" for c in dyn_cols],\n",
    "        )\n",
    "        recency_parts.append(rec_df)\n",
    "\n",
    "    rec_all = pd.concat(recency_parts).sort_index()\n",
    "\n",
    "    # Apply LOW value preprocessing (ffill then 0)\n",
    "    out[feature_cols] = (\n",
    "        out.groupby(PATIENT_COL, sort=False)[feature_cols]\n",
    "           .ffill()\n",
    "           .fillna(0.0)\n",
    "    )\n",
    "\n",
    "    # Append recency columns\n",
    "    out = pd.concat([out, rec_all], axis=1)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing: train_fit.csv ===\n",
      "Rows: 1180166 | Feature cols: 40\n",
      "Wrote LOW : train_fit_LOW_PREPROC_NO_FE.csv shape: (1180166, 43)\n",
      "Wrote HIGH: train_fit_HIGH_PREPROC_NO_FE.csv shape: (1180166, 78)\n",
      "\n",
      "=== Processing: train_thresh.csv ===\n",
      "Rows: 61120 | Feature cols: 40\n",
      "Wrote LOW : train_thresh_LOW_PREPROC_NO_FE.csv shape: (61120, 43)\n",
      "Wrote HIGH: train_thresh_HIGH_PREPROC_NO_FE.csv shape: (61120, 78)\n",
      "\n",
      "=== Processing: test.csv ===\n",
      "Rows: 310924 | Feature cols: 40\n",
      "Wrote LOW : test_LOW_PREPROC_NO_FE.csv shape: (310924, 43)\n",
      "Wrote HIGH: test_HIGH_PREPROC_NO_FE.csv shape: (310924, 78)\n",
      "\n",
      "DONE preprocessing.\n",
      "train_fit_high: /teamspace/studios/this_studio/detecting_Sepsis/data/High_Preproc_NoFe_CSV/train_fit_HIGH_PREPROC_NO_FE.csv\n",
      "train_thresh_high: /teamspace/studios/this_studio/detecting_Sepsis/data/High_Preproc_NoFe_CSV/train_thresh_HIGH_PREPROC_NO_FE.csv\n",
      "test_high: /teamspace/studios/this_studio/detecting_Sepsis/data/High_Preproc_NoFe_CSV/test_HIGH_PREPROC_NO_FE.csv\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_write(in_path: Path, low_dir: Path, high_dir: Path):\n",
    "    print(f\"\\n=== Processing: {in_path.name} ===\")\n",
    "    df = load_raw_csv(in_path)\n",
    "\n",
    "    # basic checks\n",
    "    for c in [PATIENT_COL, TIME_COL, LABEL_COL]:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"{in_path.name}: missing required column '{c}'\")\n",
    "\n",
    "    feature_cols = get_feature_cols(df)\n",
    "    print(\"Rows:\", len(df), \"| Feature cols:\", len(feature_cols))\n",
    "\n",
    "    df_low = make_low_preproc(df, feature_cols)\n",
    "    df_high = make_high_preproc(df, feature_cols, decay=RECENCY_DECAY)\n",
    "\n",
    "    low_out  = low_dir  / in_path.name.replace(\".csv\", \"_LOW_PREPROC_NO_FE.csv\")\n",
    "    high_out = high_dir / in_path.name.replace(\".csv\", \"_HIGH_PREPROC_NO_FE.csv\")\n",
    "\n",
    "    df_low.to_csv(low_out, index=False)\n",
    "    df_high.to_csv(high_out, index=False)\n",
    "\n",
    "    print(\"Wrote LOW :\", low_out.name,  \"shape:\", df_low.shape)\n",
    "    print(\"Wrote HIGH:\", high_out.name, \"shape:\", df_high.shape)\n",
    "    return low_out, high_out\n",
    "\n",
    "train_fit_low, train_fit_high = preprocess_and_write(TRAIN_FIT_CSV, LOW_DIR, HIGH_DIR)\n",
    "train_thresh_low, train_thresh_high = preprocess_and_write(TRAIN_THRESH_CSV, LOW_DIR, HIGH_DIR)\n",
    "test_low, test_high = preprocess_and_write(TEST_CSV, LOW_DIR, HIGH_DIR)\n",
    "\n",
    "print(\"\\nDONE preprocessing.\")\n",
    "print(\"train_fit_high:\", train_fit_high)\n",
    "print(\"train_thresh_high:\", train_thresh_high)\n",
    "print(\"test_high:\", test_high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote train_fit_LOW_PREPROC_WITH_MISSING.csv | added 40 miss_* columns\n",
      "Wrote train_thresh_LOW_PREPROC_WITH_MISSING.csv | added 40 miss_* columns\n",
      "Wrote test_LOW_PREPROC_WITH_MISSING.csv | added 40 miss_* columns\n",
      "\n",
      "DONE → use CSVs from: /teamspace/studios/this_studio/detecting_Sepsis/data/Low_Preproc_WithMissing_CSV\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Create LOW + Missingness CSVs (from RAW + LOW)\n",
    "# ============================================================\n",
    "\n",
    "OUT_DIR = DATA_DIR / \"Low_Preproc_WithMissing_CSV\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def drop_unnamed(df):\n",
    "    return df.loc[:, ~df.columns.str.contains(r\"^Unnamed\")]\n",
    "\n",
    "def add_missingness(raw_path: Path, low_path: Path, out_path: Path):\n",
    "    raw = drop_unnamed(pd.read_csv(raw_path))\n",
    "    low = drop_unnamed(pd.read_csv(low_path))\n",
    "\n",
    "    # feature columns = LOW features (excluding id/time/label)\n",
    "    drop_cols = {PATIENT_COL, TIME_COL, LABEL_COL}\n",
    "    feat_cols = [c for c in low.columns if c not in drop_cols]\n",
    "\n",
    "    # ensure RAW has same feature columns\n",
    "    for c in feat_cols:\n",
    "        if c not in raw.columns:\n",
    "            raw[c] = np.nan\n",
    "\n",
    "    raw = raw.sort_values([PATIENT_COL, TIME_COL]).reset_index(drop=True)\n",
    "    low = low.sort_values([PATIENT_COL, TIME_COL]).reset_index(drop=True)\n",
    "\n",
    "    # missingness from RAW (before ffill!)\n",
    "    miss = raw[feat_cols].apply(pd.to_numeric, errors=\"coerce\").isna().astype(np.int8)\n",
    "    miss.columns = [f\"miss_{c}\" for c in miss.columns]\n",
    "\n",
    "    miss_df = pd.concat([raw[[PATIENT_COL, TIME_COL]], miss], axis=1)\n",
    "\n",
    "    merged = low.merge(\n",
    "        miss_df,\n",
    "        on=[PATIENT_COL, TIME_COL],\n",
    "        how=\"left\",\n",
    "        validate=\"one_to_one\"\n",
    "    )\n",
    "\n",
    "    if len(merged) != len(low):\n",
    "        raise RuntimeError(\"Row mismatch after merge\")\n",
    "\n",
    "    merged.to_csv(out_path, index=False)\n",
    "    print(f\"Wrote {out_path.name} | added {miss.shape[1]} miss_* columns\")\n",
    "\n",
    "# --- run for all splits ---\n",
    "add_missingness(\n",
    "    RAW_CSV_DIR / \"train_fit.csv\",\n",
    "    LOW_DIR / \"train_fit_LOW_PREPROC_NO_FE.csv\",\n",
    "    OUT_DIR / \"train_fit_LOW_PREPROC_WITH_MISSING.csv\",\n",
    ")\n",
    "\n",
    "add_missingness(\n",
    "    RAW_CSV_DIR / \"train_thresh.csv\",\n",
    "    LOW_DIR / \"train_thresh_LOW_PREPROC_NO_FE.csv\",\n",
    "    OUT_DIR / \"train_thresh_LOW_PREPROC_WITH_MISSING.csv\",\n",
    ")\n",
    "\n",
    "add_missingness(\n",
    "    RAW_CSV_DIR / \"test.csv\",\n",
    "    LOW_DIR / \"test_LOW_PREPROC_NO_FE.csv\",\n",
    "    OUT_DIR / \"test_LOW_PREPROC_WITH_MISSING.csv\",\n",
    ")\n",
    "\n",
    "print(\"\\nDONE → use CSVs from:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote train_fit_high_preproc_Mean_Impute.csv | shape=(1180166, 78)\n",
      "Wrote train_thresh_high_preproc_Mean_Impute.csv | shape=(61120, 78)\n",
      "Wrote test_high_preproc_Mean_Impute.csv | shape=(310924, 78)\n",
      "\n",
      "DONE → use CSVs from: /teamspace/studios/this_studio/detecting_Sepsis/data/High_Preproc_TrainMeanImpute_CSV\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Create HIGH-preproc CSVs (from RAW) with:\n",
    "#   - per-patient forward-fill\n",
    "#   - recency_* features (computed from RAW missingness BEFORE ffill)\n",
    "#   - remaining NaNs imputed with GLOBAL TRAINING MEAN (fit on RAW train_fit)\n",
    "#\n",
    "# Writes 3 CSVs:\n",
    "#   - train_fit_high_preproc_Mean_Impute.csv\n",
    "#   - train_thresh_high_preproc_Mean_Impute.csv\n",
    "#   - test_high_preproc_Mean_Impute.csv\n",
    "# ============================================================\n",
    "\n",
    "OUT_DIR = DATA_DIR / \"High_Preproc_TrainMeanImpute_CSV\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def drop_unnamed(df):\n",
    "    return df.loc[:, ~df.columns.str.contains(r\"^Unnamed\")]\n",
    "\n",
    "def get_feat_cols(df):\n",
    "    drop_cols = {PATIENT_COL, TIME_COL, LABEL_COL}\n",
    "    return [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "def compute_recency_from_missing(missing_mask: np.ndarray, decay: float = 0.9) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    missing_mask: shape (T, D) boolean, True if value is missing at time t for feature d\n",
    "    returns: recency in (0,1], with 1 when observed at t, else decay*previous\n",
    "    \"\"\"\n",
    "    T, D = missing_mask.shape\n",
    "    rec = np.zeros((T, D), dtype=np.float32)\n",
    "    for t in range(T):\n",
    "        if t == 0:\n",
    "            rec[t] = np.where(~missing_mask[t], 1.0, 0.0)\n",
    "        else:\n",
    "            rec[t] = np.where(~missing_mask[t], 1.0, decay * rec[t - 1])\n",
    "    return rec\n",
    "\n",
    "def make_high_preproc_with_trainmean_impute(\n",
    "    raw_path: Path,\n",
    "    out_path: Path,\n",
    "    feat_cols: list,\n",
    "    train_means: pd.Series,\n",
    "    decay: float = 0.9,\n",
    "):\n",
    "    raw = drop_unnamed(pd.read_csv(raw_path))\n",
    "    raw = raw.sort_values([PATIENT_COL, TIME_COL]).reset_index(drop=True)\n",
    "\n",
    "    # ensure all feat_cols exist (in case columns differ across splits)\n",
    "    for c in feat_cols:\n",
    "        if c not in raw.columns:\n",
    "            raw[c] = np.nan\n",
    "\n",
    "    # coerce to numeric for feature columns\n",
    "    raw[feat_cols] = raw[feat_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # dynamic cols for recency\n",
    "    dyn_cols = [c for c in feat_cols if c not in NO_RECENCY_COLS]\n",
    "\n",
    "    recency_parts = []\n",
    "    # compute recency per patient from RAW missingness pattern\n",
    "    for pid, g in raw.groupby(PATIENT_COL, sort=False):\n",
    "        miss = g[dyn_cols].isna().to_numpy(dtype=bool, copy=False)\n",
    "        rec = compute_recency_from_missing(miss, decay=decay)\n",
    "        rec_df = pd.DataFrame(rec, index=g.index, columns=[f\"recency_{c}\" for c in dyn_cols])\n",
    "        recency_parts.append(rec_df)\n",
    "\n",
    "    rec_all = pd.concat(recency_parts, axis=0).sort_index()\n",
    "\n",
    "    # HIGH values: forward fill within patient\n",
    "    high = raw.copy()\n",
    "    high[feat_cols] = high.groupby(PATIENT_COL, sort=False)[feat_cols].ffill()\n",
    "\n",
    "    # remaining NaNs -> GLOBAL TRAINING MEAN (fit on RAW train_fit)\n",
    "    # (align ensures columns match even if order differs)\n",
    "    high[feat_cols] = high[feat_cols].fillna(train_means.reindex(feat_cols))\n",
    "\n",
    "    # append recency columns\n",
    "    high = pd.concat([high, rec_all], axis=1)\n",
    "\n",
    "    high.to_csv(out_path, index=False)\n",
    "    print(f\"Wrote {out_path.name} | shape={high.shape}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Fit GLOBAL TRAINING MEANS on RAW train_fit\n",
    "# ------------------------------------------------------------\n",
    "raw_train_fit = drop_unnamed(pd.read_csv(TRAIN_FIT_CSV))\n",
    "raw_train_fit = raw_train_fit.sort_values([PATIENT_COL, TIME_COL]).reset_index(drop=True)\n",
    "\n",
    "feat_cols = get_feat_cols(raw_train_fit)\n",
    "\n",
    "tmp = raw_train_fit.copy()\n",
    "tmp[feat_cols] = tmp[feat_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "train_means = tmp[feat_cols].mean(axis=0, skipna=True)\n",
    "\n",
    "# if a feature is entirely NaN in train_fit -> mean is NaN; fall back to 0.0 (change if you want)\n",
    "train_means = train_means.fillna(0.0)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Create HIGH-preproc splits with train-mean imputation\n",
    "# ------------------------------------------------------------\n",
    "make_high_preproc_with_trainmean_impute(\n",
    "    raw_path=TRAIN_FIT_CSV,\n",
    "    out_path=OUT_DIR / \"train_fit_high_preproc_Mean_Impute.csv\",\n",
    "    feat_cols=feat_cols,\n",
    "    train_means=train_means,\n",
    "    decay=RECENCY_DECAY if \"RECENCY_DECAY\" in globals() else 0.9,\n",
    ")\n",
    "\n",
    "make_high_preproc_with_trainmean_impute(\n",
    "    raw_path=TRAIN_THRESH_CSV,\n",
    "    out_path=OUT_DIR / \"train_thresh_high_preproc_Mean_Impute.csv\",\n",
    "    feat_cols=feat_cols,\n",
    "    train_means=train_means,\n",
    "    decay=RECENCY_DECAY if \"RECENCY_DECAY\" in globals() else 0.9,\n",
    ")\n",
    "\n",
    "make_high_preproc_with_trainmean_impute(\n",
    "    raw_path=TEST_CSV,\n",
    "    out_path=OUT_DIR / \"test_high_preproc_Mean_Impute.csv\",\n",
    "    feat_cols=feat_cols,\n",
    "    train_means=train_means,\n",
    "    decay=RECENCY_DECAY if \"RECENCY_DECAY\" in globals() else 0.9,\n",
    ")\n",
    "\n",
    "print(\"\\nDONE → use CSVs from:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample pid: 11\n",
      "Rows: 34\n",
      "ICULOS head: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "ICULOS tail: [26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check: pick one patient from train_thresh_high and verify monotonic time ordering\n",
    "df_check = pd.read_csv(train_thresh_high)\n",
    "pid = int(df_check[PATIENT_COL].iloc[0])\n",
    "g = df_check[df_check[PATIENT_COL] == pid].sort_values(TIME_COL)\n",
    "\n",
    "print(\"Sample pid:\", pid)\n",
    "print(\"Rows:\", len(g))\n",
    "print(\"ICULOS head:\", g[TIME_COL].head(10).tolist())\n",
    "print(\"ICULOS tail:\", g[TIME_COL].tail(10).tolist())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
