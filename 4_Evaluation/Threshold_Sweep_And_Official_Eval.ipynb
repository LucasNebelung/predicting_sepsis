{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "247839ed",
   "metadata": {},
   "source": [
    "# Threshold Sweep + Official PhysioNet 2019 Evaluation\n",
    "\n",
    "- **Model scripts (e.g., LightGBM, TimesLib)** only write `_WORK` folders containing continuous scores (e.g., `PredictedProbability`).\n",
    "- **This notebook** is the *single source of truth* for:\n",
    "  - Threshold sweep on **TRAIN_THRESH** (utility via official evaluator)\n",
    "  - Selecting best threshold\n",
    "  - Writing final TimesLib-style folders:\n",
    "    - `pred_psv_TRAIN_THRESH`\n",
    "    - `pred_psv_TEST`\n",
    "  - Official metrics + plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb445db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parent: /teamspace/studios/this_studio/detecting_Sepsis/3_Model/Time-Series-Library/results/classification_Sepsis_TFT_HIGH_Mean_Impute_TemporalFusionTransformer_SepsisCSV_ftM_sl48_ll48_pl0_dm64_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_TFT_on_CSV_High_Mean_Impute_0\n",
      "Repo root: /teamspace/studios/this_studio/detecting_Sepsis\n",
      "Label TRAIN_THRESH: /teamspace/studios/this_studio/detecting_Sepsis/data/raw_PSV/PSV_Patients_THRESH\n",
      "Label TEST: /teamspace/studios/this_studio/detecting_Sepsis/data/raw_PSV/PSV_Patients_TEST\n",
      "Pred source TRAIN: /teamspace/studios/this_studio/detecting_Sepsis/3_Model/Time-Series-Library/results/classification_Sepsis_TFT_HIGH_Mean_Impute_TemporalFusionTransformer_SepsisCSV_ftM_sl48_ll48_pl0_dm64_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_TFT_on_CSV_High_Mean_Impute_0/pred_psv_TRAIN_THRESH_WORK\n",
      "Pred source TEST: /teamspace/studios/this_studio/detecting_Sepsis/3_Model/Time-Series-Library/results/classification_Sepsis_TFT_HIGH_Mean_Impute_TemporalFusionTransformer_SepsisCSV_ftM_sl48_ll48_pl0_dm64_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_TFT_on_CSV_High_Mean_Impute_0/pred_psv_TEST_WORK\n",
      "Running TWO-STAGE threshold sweep on TRAIN_THRESH (no cache)...\n",
      "[Stage 1/2] Coarse sweep: step=0.01 (101 thresholds)\n",
      "  NEW BEST (coarse) t=0.0000 util=-0.604016\n",
      "  NEW BEST (coarse) t=0.0200 util=-0.491602\n",
      "  NEW BEST (coarse) t=0.0300 util=-0.339833\n",
      "  NEW BEST (coarse) t=0.0400 util=-0.217206\n",
      "  NEW BEST (coarse) t=0.0500 util=-0.122921\n",
      "  NEW BEST (coarse) t=0.0600 util=-0.045956\n",
      "  NEW BEST (coarse) t=0.0700 util=0.019049\n",
      "  NEW BEST (coarse) t=0.0800 util=0.070633\n",
      "  NEW BEST (coarse) t=0.0900 util=0.112108\n",
      "  Coarse progress 10/101 (latest t=0.0900, util=0.112108)\n",
      "  NEW BEST (coarse) t=0.1000 util=0.149327\n",
      "  NEW BEST (coarse) t=0.1100 util=0.181182\n",
      "  NEW BEST (coarse) t=0.1200 util=0.209231\n",
      "  NEW BEST (coarse) t=0.1300 util=0.238334\n",
      "  NEW BEST (coarse) t=0.1400 util=0.261935\n",
      "  NEW BEST (coarse) t=0.1500 util=0.282716\n",
      "  NEW BEST (coarse) t=0.1600 util=0.300968\n",
      "  NEW BEST (coarse) t=0.1700 util=0.318186\n",
      "  NEW BEST (coarse) t=0.1800 util=0.331483\n",
      "  NEW BEST (coarse) t=0.1900 util=0.340558\n",
      "  Coarse progress 20/101 (latest t=0.1900, util=0.340558)\n",
      "  NEW BEST (coarse) t=0.2000 util=0.348560\n",
      "  NEW BEST (coarse) t=0.2100 util=0.355747\n",
      "  NEW BEST (coarse) t=0.2200 util=0.365864\n",
      "  NEW BEST (coarse) t=0.2300 util=0.371331\n",
      "  NEW BEST (coarse) t=0.2400 util=0.376411\n",
      "  NEW BEST (coarse) t=0.2500 util=0.381401\n",
      "  NEW BEST (coarse) t=0.2600 util=0.382219\n",
      "  Coarse progress 30/101 (latest t=0.2900, util=0.372062)\n",
      "  Coarse progress 40/101 (latest t=0.3900, util=0.327734)\n",
      "  Coarse progress 50/101 (latest t=0.4900, util=0.286957)\n",
      "  Coarse progress 60/101 (latest t=0.5900, util=0.222696)\n",
      "  Coarse progress 70/101 (latest t=0.6900, util=0.136551)\n",
      "  Coarse progress 80/101 (latest t=0.7900, util=0.062439)\n",
      "  Coarse progress 90/101 (latest t=0.8900, util=0.005086)\n",
      "  Coarse progress 100/101 (latest t=0.9900, util=0.000000)\n",
      "[Stage 2/2] Refine around 0.2600: [0.2585, 0.2615] step=0.00015 (20 thresholds)\n",
      "Best threshold by utility: 0.2615\n",
      "Saved sweep: /teamspace/studios/this_studio/detecting_Sepsis/3_Model/Time-Series-Library/results/classification_Sepsis_TFT_HIGH_Mean_Impute_TemporalFusionTransformer_SepsisCSV_ftM_sl48_ll48_pl0_dm64_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_TFT_on_CSV_High_Mean_Impute_0/thresh_sweep_results.csv\n",
      "Saved plot: /teamspace/studios/this_studio/detecting_Sepsis/3_Model/Time-Series-Library/results/classification_Sepsis_TFT_HIGH_Mean_Impute_TemporalFusionTransformer_SepsisCSV_ftM_sl48_ll48_pl0_dm64_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_TFT_on_CSV_High_Mean_Impute_0/utility_vs_threshold.png\n",
      "Wrote final TRAIN folder: /teamspace/studios/this_studio/detecting_Sepsis/3_Model/Time-Series-Library/results/classification_Sepsis_TFT_HIGH_Mean_Impute_TemporalFusionTransformer_SepsisCSV_ftM_sl48_ll48_pl0_dm64_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_TFT_on_CSV_High_Mean_Impute_0/pred_psv_TRAIN_THRESH_THRESHED\n",
      "Wrote final TEST folder: /teamspace/studios/this_studio/detecting_Sepsis/3_Model/Time-Series-Library/results/classification_Sepsis_TFT_HIGH_Mean_Impute_TemporalFusionTransformer_SepsisCSV_ftM_sl48_ll48_pl0_dm64_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_TFT_on_CSV_High_Mean_Impute_0/pred_psv_TEST_THRESHED\n",
      "Saved metrics: /teamspace/studios/this_studio/detecting_Sepsis/3_Model/Time-Series-Library/results/classification_Sepsis_TFT_HIGH_Mean_Impute_TemporalFusionTransformer_SepsisCSV_ftM_sl48_ll48_pl0_dm64_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_TFT_on_CSV_High_Mean_Impute_0/final_metrics_official.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_parent_dir': '/teamspace/studios/this_studio/detecting_Sepsis/3_Model/Time-Series-Library/results/classification_Sepsis_TFT_HIGH_Mean_Impute_TemporalFusionTransformer_SepsisCSV_ftM_sl48_ll48_pl0_dm64_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_TFT_on_CSV_High_Mean_Impute_0',\n",
       " 'best_threshold': 0.2615,\n",
       " 'train_thresh': {'auroc': np.float64(0.8239374005123444),\n",
       "  'auprc': np.float64(0.08735154399897739),\n",
       "  'accuracy': 0.7779450261780104,\n",
       "  'f_measure': 0.10604663417204585,\n",
       "  'utility': np.float64(0.383405760182216)},\n",
       " 'test': {'auroc': np.float64(0.8402254302517654),\n",
       "  'auprc': np.float64(0.12145947896272234),\n",
       "  'accuracy': 0.7584618749276351,\n",
       "  'f_measure': 0.10315507893668346,\n",
       "  'utility': np.float64(0.39365348299535835)}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Threshold Sweep + Official PhysioNet 2019 Evaluation\n",
    "# SAFE + MODEL-AGNOSTIC + Option B\n",
    "#\n",
    "# You set ONLY:\n",
    "#   MODEL_PARENT_DIR\n",
    "#\n",
    "# Works for:\n",
    "# - TimesLib: .../Predictions/TimesLib/<ModelName>/\n",
    "#   (expects pred_psv_TRAIN_THRESH_WORK and optionally pred_psv_TEST)\n",
    "# - LightGBM: .../Predictions/LIGHTGBM/\n",
    "#   (expects pred_psv_TRAIN_THRESH_WORK and pred_psv_TEST_WORK)\n",
    "#\n",
    "# Key safety:\n",
    "# - NEVER overwrites/deletes your existing pred_psv_* folders\n",
    "# - Writes final thresholded outputs into *_THRESHED folders\n",
    "# ============================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "import importlib.util\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ============================\n",
    "# CONFIG (EDIT ONLY THIS)\n",
    "# ============================\n",
    "\n",
    "#MODEL_PARENT_DIR = Path(\"/teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/TimesLib/Crossformer_HighPreproc_NoFe\")\n",
    "#MODEL_PARENT_DIR = Path(\"/teamspace/studios/this_studio/detecting_Sepsis/3_Model/Time-Series-Library/results/classification_Sepsis_TFT_HIGH_TemporalFusionTransformer_SepsisPSV_ftM_sl48_ll48_pl0_dm64_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_HIGH_PREPROC_NO_FE_0\")\n",
    "#MODEL_PARENT_DIR = Path(\"/teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/LIGHTGBM_No_Preproc\")\n",
    "#MODEL_PARENT_DIR = Path(\"/teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/TimesLib/TFT_HighPreproc_NoFe\")\n",
    "#MODEL_PARENT_DIR =Path(\"/teamspace/studios/this_studio/detecting_Sepsis/3_Model/Time-Series-Library/results/classification_Sepsis_TFT_HIGH_TemporalFusionTransformer_SepsisPSV_ftM_sl48_ll48_pl0_dm64_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_TFT_seq48_bs512_lr1e-4_dm64_df256_do03_p1_pw20_NOsampler_clip1_0\")\n",
    "#MODEL_PARENT_DIR =Path(\"/teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/qSOFA_aggresive_Alarm_Policy\")\n",
    "MODEL_PARENT_DIR = Path (\"/teamspace/studios/this_studio/detecting_Sepsis/3_Model/Time-Series-Library/results/classification_Sepsis_TFT_HIGH_Mean_Impute_TemporalFusionTransformer_SepsisCSV_ftM_sl48_ll48_pl0_dm64_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_TFT_on_CSV_High_Mean_Impute_0\")\n",
    "\n",
    "# Original Setup \n",
    "# Two-stage sweep params (fast + good)\n",
    "#COARSE_STEP = 0.05\n",
    "#REFINE_HALF_WIDTH = 0.03\n",
    "#REFINE_STEP = 0.003\n",
    "\n",
    "# slower, more accurate setup\n",
    "COARSE_STEP = 0.01\n",
    "REFINE_HALF_WIDTH = 0.0015\n",
    "REFINE_STEP = 0.00015\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Helper: locate repo root + label dirs\n",
    "# ============================\n",
    "def find_repo_root_from_model_dir(model_parent_dir: Path) -> Path:\n",
    "    parts = model_parent_dir.resolve().parts\n",
    "    if \"detecting_Sepsis\" not in parts:\n",
    "        raise ValueError(f\"MODEL_PARENT_DIR must contain 'detecting_Sepsis' in its path: {model_parent_dir}\")\n",
    "    i = parts.index(\"detecting_Sepsis\")\n",
    "    return Path(*parts[: i + 1])\n",
    "\n",
    "def get_label_dirs(repo_root: Path) -> tuple[Path, Path]:\n",
    "    train_thresh = repo_root / \"data\" / \"raw_PSV\" / \"PSV_Patients_THRESH\"\n",
    "    test = repo_root / \"data\" / \"raw_PSV\" / \"PSV_Patients_TEST\"\n",
    "    if not train_thresh.exists():\n",
    "        raise FileNotFoundError(f\"Missing label dir: {train_thresh}\")\n",
    "    if not test.exists():\n",
    "        print(f\"WARNING: Missing TEST label dir: {test} (TEST eval will be skipped)\")\n",
    "    return train_thresh, test\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Helper: find prediction dirs (TimesLib + LightGBM compatible)\n",
    "# ============================\n",
    "def dir_has_psv(d: Path) -> bool:\n",
    "    return d.exists() and any(d.glob(\"*.psv\"))\n",
    "\n",
    "def pick_existing_dir_with_psv(parent: Path, candidates: list[str], required: bool) -> Path | None:\n",
    "    for c in candidates:\n",
    "        p = parent / c\n",
    "        if dir_has_psv(p):\n",
    "            return p\n",
    "    if required:\n",
    "        raise FileNotFoundError(f\"No .psv files found in any of: {[(parent / c) for c in candidates]}\")\n",
    "    return None\n",
    "\n",
    "def get_pred_dirs(model_parent_dir: Path) -> tuple[Path, Path | None]:\n",
    "    # TRAIN is required\n",
    "    train_dir = pick_existing_dir_with_psv(\n",
    "        model_parent_dir,\n",
    "        [\"pred_psv_TRAIN_THRESH_WORK\", \"pred_psv_TRAIN_THRESH\"],\n",
    "        required=True\n",
    "    )\n",
    "\n",
    "    # TEST is optional\n",
    "    test_dir = pick_existing_dir_with_psv(\n",
    "        model_parent_dir,\n",
    "        [\"pred_psv_TEST_WORK\", \"pred_psv_TEST\"],\n",
    "        required=False\n",
    "    )\n",
    "    if test_dir is None:\n",
    "        print(\"NOTE: No TEST prediction .psv found (pred_psv_TEST_WORK/pred_psv_TEST). Skipping TEST outputs.\")\n",
    "\n",
    "    return train_dir, test_dir\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Official evaluator\n",
    "# ============================\n",
    "def load_official_evaluator(repo_root: Path):\n",
    "    eval_script = repo_root / \"4_Evaluation\" / \"evaluate_sepsis_score.py\"\n",
    "    if not eval_script.exists():\n",
    "        raise FileNotFoundError(f\"Official evaluator not found: {eval_script}\")\n",
    "    spec = importlib.util.spec_from_file_location(\"eval_sepsis\", str(eval_script))\n",
    "    if spec is None or spec.loader is None:\n",
    "        raise RuntimeError(f\"Could not import evaluator from {eval_script}\")\n",
    "    mod = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(mod)\n",
    "    return mod\n",
    "\n",
    "def official_eval(evaluator_module, label_dir: Path, pred_dir: Path):\n",
    "    # returns: auroc, auprc, accuracy, f_measure, normalized_observed_utility\n",
    "    return evaluator_module.evaluate_sepsis_score(str(label_dir), str(pred_dir))\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Materialization (SAFE: writes to *_THRESHED only)\n",
    "# ============================\n",
    "def detect_score_column(df: pd.DataFrame) -> str:\n",
    "    # ignore model-provided PredictedLabel; only use score/prob column\n",
    "    candidates = [\"PredictedProbability\"]\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise ValueError(f\"No score column found. Columns: {list(df.columns)}\")\n",
    "\n",
    "def ensure_empty_dir(dir_path: Path):\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    for f in dir_path.glob(\"*.psv\"):\n",
    "        f.unlink()\n",
    "\n",
    "def write_pred_file_for_official(out_path: Path, prob: np.ndarray, threshold: float):\n",
    "    pred = (prob >= threshold).astype(int)\n",
    "    out_df = pd.DataFrame({\n",
    "        \"PredictedProbability\": prob.astype(float),\n",
    "        \"PredictedLabel\": pred.astype(int),\n",
    "    })\n",
    "    out_df.to_csv(out_path, sep=\"|\", index=False)\n",
    "\n",
    "def materialize_predictions_from_source(source_dir: Path, out_dir: Path, threshold: float):\n",
    "    \"\"\"\n",
    "    Reads .psv from source_dir (probabilities)\n",
    "    Writes official-format .psv into out_dir (prob + label)\n",
    "    SAFE because out_dir is distinct from source_dir (we enforce that in naming).\n",
    "    \"\"\"\n",
    "    files = sorted(source_dir.glob(\"*.psv\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No .psv files found in: {source_dir}\")\n",
    "\n",
    "    ensure_empty_dir(out_dir)\n",
    "\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f, sep=\"|\")\n",
    "        score_col = detect_score_column(df)\n",
    "        prob = df[score_col].astype(float).to_numpy()\n",
    "        write_pred_file_for_official(out_dir / f.name, prob, threshold)\n",
    "\n",
    "def label_dir_has_sepsislabel(label_dir: Path) -> bool:\n",
    "    files = list(label_dir.glob(\"*.psv\"))\n",
    "    if not files:\n",
    "        return False\n",
    "    df = pd.read_csv(files[0], sep=\"|\", nrows=2)\n",
    "    return \"SepsisLabel\" in df.columns\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Two-stage sweep (TRAIN_THRESH ONLY)\n",
    "# ============================\n",
    "def run_threshold_sweep_two_stage(\n",
    "    evaluator,\n",
    "    label_dir_train_thresh: Path,\n",
    "    pred_source_train: Path,\n",
    "    tmp_pred_dir: Path,\n",
    "    coarse_step: float,\n",
    "    refine_half_width: float,\n",
    "    refine_step: float,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    coarse = np.round(np.arange(0.0, 1.0 + 1e-12, coarse_step), 6)\n",
    "\n",
    "    rows = []\n",
    "    best_coarse_t = None\n",
    "    best_coarse_util = -1e18\n",
    "\n",
    "    print(f\"[Stage 1/2] Coarse sweep: step={coarse_step} ({len(coarse)} thresholds)\")\n",
    "    for i, t in enumerate(coarse, 1):\n",
    "        materialize_predictions_from_source(pred_source_train, tmp_pred_dir, float(t))\n",
    "        auroc, auprc, acc, f1, util = official_eval(evaluator, label_dir_train_thresh, tmp_pred_dir)\n",
    "        rows.append((float(t), float(util), float(auroc), float(auprc), float(acc), float(f1)))\n",
    "\n",
    "        if util > best_coarse_util:\n",
    "            best_coarse_util = float(util)\n",
    "            best_coarse_t = float(t)\n",
    "            print(f\"  NEW BEST (coarse) t={best_coarse_t:.4f} util={best_coarse_util:.6f}\")\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"  Coarse progress {i}/{len(coarse)} (latest t={t:.4f}, util={float(util):.6f})\")\n",
    "\n",
    "    lo = max(0.0, best_coarse_t - refine_half_width)\n",
    "    hi = min(1.0, best_coarse_t + refine_half_width)\n",
    "    refine = np.round(np.arange(lo, hi + 1e-12, refine_step), 6)\n",
    "\n",
    "    # avoid duplicates\n",
    "    done = set(np.round(coarse, 6).tolist())\n",
    "    refine = np.array([t for t in refine if float(t) not in done], dtype=float)\n",
    "\n",
    "    print(\n",
    "        f\"[Stage 2/2] Refine around {best_coarse_t:.4f}: \"\n",
    "        f\"[{lo:.4f}, {hi:.4f}] step={refine_step} ({len(refine)} thresholds)\"\n",
    "    )\n",
    "\n",
    "    for i, t in enumerate(refine, 1):\n",
    "        materialize_predictions_from_source(pred_source_train, tmp_pred_dir, float(t))\n",
    "        auroc, auprc, acc, f1, util = official_eval(evaluator, label_dir_train_thresh, tmp_pred_dir)\n",
    "        rows.append((float(t), float(util), float(auroc), float(auprc), float(acc), float(f1)))\n",
    "\n",
    "        if i % 25 == 0:\n",
    "            print(f\"  Refine progress {i}/{len(refine)} (latest t={t:.4f}, util={float(util):.6f})\")\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"threshold\", \"utility\", \"auroc\", \"auprc\", \"accuracy\", \"f1\"])\n",
    "    df = df.sort_values(\"threshold\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def pick_best_threshold(df: pd.DataFrame) -> float:\n",
    "    best_row = df.sort_values([\"utility\", \"threshold\"], ascending=[False, True]).iloc[0]\n",
    "    return float(best_row[\"threshold\"])\n",
    "\n",
    "def plot_utility(df: pd.DataFrame, out_png: Path):\n",
    "    plt.figure()\n",
    "    plt.plot(df[\"threshold\"].to_numpy(), df[\"utility\"].to_numpy())\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Utility (official)\")\n",
    "    plt.title(\"PhysioNet 2019 Utility vs Threshold\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ============================\n",
    "# RUN\n",
    "# ============================\n",
    "MODEL_PARENT_DIR = MODEL_PARENT_DIR.resolve()\n",
    "repo_root = find_repo_root_from_model_dir(MODEL_PARENT_DIR)\n",
    "LABEL_DIR_TRAIN_THRESH, LABEL_DIR_TEST = get_label_dirs(repo_root)\n",
    "\n",
    "PRED_SOURCE_TRAIN, PRED_SOURCE_TEST = get_pred_dirs(MODEL_PARENT_DIR)\n",
    "\n",
    "print(\"Model parent:\", MODEL_PARENT_DIR)\n",
    "print(\"Repo root:\", repo_root)\n",
    "print(\"Label TRAIN_THRESH:\", LABEL_DIR_TRAIN_THRESH)\n",
    "print(\"Label TEST:\", LABEL_DIR_TEST)\n",
    "print(\"Pred source TRAIN:\", PRED_SOURCE_TRAIN)\n",
    "print(\"Pred source TEST:\", PRED_SOURCE_TEST)\n",
    "\n",
    "# Outputs (never overwrite originals)\n",
    "THRESH_SWEEP_CSV   = MODEL_PARENT_DIR / \"thresh_sweep_results.csv\"\n",
    "UTILITY_PLOT_PNG   = MODEL_PARENT_DIR / \"utility_vs_threshold.png\"\n",
    "FINAL_METRICS_JSON = MODEL_PARENT_DIR / \"final_metrics_official.json\"\n",
    "FINAL_TRAIN_DIR    = MODEL_PARENT_DIR / \"pred_psv_TRAIN_THRESH_THRESHED\"\n",
    "FINAL_TEST_DIR     = MODEL_PARENT_DIR / \"pred_psv_TEST_THRESHED\"\n",
    "\n",
    "# Temp dir for evaluator per-threshold files (safe)\n",
    "TMP_PRED_DIR = MODEL_PARENT_DIR / \"_tmp_pred_sweep\"\n",
    "TMP_PRED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "evaluator = load_official_evaluator(repo_root)\n",
    "\n",
    "print(\"Running TWO-STAGE threshold sweep on TRAIN_THRESH (no cache)...\")\n",
    "df_sweep = run_threshold_sweep_two_stage(\n",
    "    evaluator=evaluator,\n",
    "    label_dir_train_thresh=LABEL_DIR_TRAIN_THRESH,\n",
    "    pred_source_train=PRED_SOURCE_TRAIN,\n",
    "    tmp_pred_dir=TMP_PRED_DIR,\n",
    "    coarse_step=COARSE_STEP,\n",
    "    refine_half_width=REFINE_HALF_WIDTH,\n",
    "    refine_step=REFINE_STEP,\n",
    ")\n",
    "\n",
    "best_t = pick_best_threshold(df_sweep)\n",
    "print(\"Best threshold by utility:\", best_t)\n",
    "\n",
    "# Save artifacts\n",
    "df_sweep.to_csv(THRESH_SWEEP_CSV, index=False)\n",
    "plot_utility(df_sweep, UTILITY_PLOT_PNG)\n",
    "print(\"Saved sweep:\", THRESH_SWEEP_CSV)\n",
    "print(\"Saved plot:\", UTILITY_PLOT_PNG)\n",
    "\n",
    "# Write final thresholded outputs (SAFE folders)\n",
    "materialize_predictions_from_source(PRED_SOURCE_TRAIN, FINAL_TRAIN_DIR, best_t)\n",
    "print(\"Wrote final TRAIN folder:\", FINAL_TRAIN_DIR)\n",
    "\n",
    "if PRED_SOURCE_TEST is not None:\n",
    "    materialize_predictions_from_source(PRED_SOURCE_TEST, FINAL_TEST_DIR, best_t)\n",
    "    print(\"Wrote final TEST folder:\", FINAL_TEST_DIR)\n",
    "else:\n",
    "    print(\"Skipped final TEST folder (no TEST predictions available).\")\n",
    "\n",
    "# Official metrics after threshold selection (TRAIN_THRESH)\n",
    "auroc, auprc, acc, f1, util = official_eval(evaluator, LABEL_DIR_TRAIN_THRESH, FINAL_TRAIN_DIR)\n",
    "final = {\n",
    "    \"model_parent_dir\": str(MODEL_PARENT_DIR),\n",
    "    \"best_threshold\": best_t,\n",
    "    \"train_thresh\": {\"auroc\": auroc, \"auprc\": auprc, \"accuracy\": acc, \"f_measure\": f1, \"utility\": util},\n",
    "}\n",
    "\n",
    "# Optional TEST official eval (only if TEST labels exist AND test preds exist)\n",
    "if (PRED_SOURCE_TEST is not None) and label_dir_has_sepsislabel(LABEL_DIR_TEST):\n",
    "    auroc, auprc, acc, f1, util = official_eval(evaluator, LABEL_DIR_TEST, FINAL_TEST_DIR)\n",
    "    final[\"test\"] = {\"auroc\": auroc, \"auprc\": auprc, \"accuracy\": acc, \"f_measure\": f1, \"utility\": util}\n",
    "else:\n",
    "    final[\"test\"] = {\"note\": \"Skipped TEST official evaluation (missing SepsisLabel or missing TEST predictions).\"}\n",
    "\n",
    "FINAL_METRRICS_DIR = FINAL_METRICS_JSON.parent\n",
    "FINAL_METRICS_JSON.write_text(json.dumps(final, indent=2))\n",
    "print(\"Saved metrics:\", FINAL_METRICS_JSON)\n",
    "\n",
    "# Cleanup temp sweep dir (optional)\n",
    "shutil.rmtree(TMP_PRED_DIR, ignore_errors=True)\n",
    "\n",
    "final\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
