{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODE_DIR: /teamspace/studios/this_studio/detecting_Sepsis/data/High_Preproc_NoFe_CSV\n",
      "TRAIN_FIT: /teamspace/studios/this_studio/detecting_Sepsis/data/High_Preproc_NoFe_CSV/train_fit_HIGH_PREPROC_NO_FE.csv\n",
      "TRAIN_THRESH: /teamspace/studios/this_studio/detecting_Sepsis/data/High_Preproc_NoFe_CSV/train_thresh_HIGH_PREPROC_NO_FE.csv\n",
      "TEST: /teamspace/studios/this_studio/detecting_Sepsis/data/High_Preproc_NoFe_CSV/test_HIGH_PREPROC_NO_FE.csv\n",
      "PRED_ROOT: /teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/LIGHTGBM_HighPreproc_NoFe\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# =========================\n",
    "# Set ONCE\n",
    "# =========================\n",
    "DATA_DIR = Path(\"/teamspace/studios/this_studio/detecting_Sepsis/data\")\n",
    "\n",
    "# Point directly to the dataset variant you want to use:\n",
    "MODE_DIR = DATA_DIR / \"SignatureFeatureSets\" / \"rich_FE__orig1_hc1_sig1_csig1_lb7_so3_cso3_ll1\"\n",
    "#MODE_DIR = DATA_DIR / \"Low_Preproc_NoFe_CSV\"\n",
    "#MODE_DIR = DATA_DIR / \"raw_CSV\"\n",
    "\n",
    "# One run folder name (used under 4_Evaluation/Predictions/)\n",
    "RUN_NAME = \"LIGHTGBM_Signatures\"   # change once per experiment\n",
    "\n",
    "# =========================\n",
    "# Conventions\n",
    "# =========================\n",
    "PATIENT_COL = \"Patient_ID\"\n",
    "TIME_COL    = \"ICULOS\"\n",
    "LABEL_COL   = \"SepsisLabel\"\n",
    "\n",
    "# =========================\n",
    "# Resolve dataset files from MODE_DIR (AUTO)\n",
    "# =========================\n",
    "def resolve_dataset_paths(mode_dir: Path):\n",
    "    if not mode_dir.exists():\n",
    "        raise FileNotFoundError(f\"MODE_DIR does not exist: {mode_dir}\")\n",
    "\n",
    "    candidates = [\n",
    "        # Signature-augmented preferred names\n",
    "        (\"train_fit_HIGH_PREPROC_NO_FE_with_signatures.csv\",\n",
    "         \"train_thresh_HIGH_PREPROC_NO_FE_with_signatures.csv\",\n",
    "         \"test_HIGH_PREPROC_NO_FE_with_signatures.csv\"),\n",
    "        # Signature fallback names\n",
    "        (\"train_fit_with_signatures.csv\",\n",
    "         \"train_thresh_with_signatures.csv\",\n",
    "         \"test_with_signatures.csv\"),\n",
    "        # HIGH\n",
    "        (\"train_fit_HIGH_PREPROC_NO_FE.csv\",\n",
    "         \"train_thresh_HIGH_PREPROC_NO_FE.csv\",\n",
    "         \"test_HIGH_PREPROC_NO_FE.csv\"),\n",
    "        # LOW\n",
    "        (\"train_fit_LOW_PREPROC_NO_FE.csv\",\n",
    "         \"train_thresh_LOW_PREPROC_NO_FE.csv\",\n",
    "         \"test_LOW_PREPROC_NO_FE.csv\"),\n",
    "        # RAW\n",
    "        (\"train_fit.csv\",\n",
    "         \"train_thresh.csv\",\n",
    "         \"test.csv\"),\n",
    "    ]\n",
    "\n",
    "    for fit, thresh, test in candidates:\n",
    "        p_fit = mode_dir / fit\n",
    "        p_thr = mode_dir / thresh\n",
    "        p_tst = mode_dir / test\n",
    "        if p_fit.exists() and p_thr.exists() and p_tst.exists():\n",
    "            return p_fit, p_thr, p_tst\n",
    "\n",
    "    # Helpful error message\n",
    "    existing = sorted([p.name for p in mode_dir.glob(\"*.csv\")])\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not resolve dataset files in MODE_DIR={mode_dir}\\n\"\n",
    "        f\"Expected one of these naming schemes:\\n\"\n",
    "        f\"  SIG : train_fit_HIGH_PREPROC_NO_FE_with_signatures.csv + train_thresh_HIGH_PREPROC_NO_FE_with_signatures.csv + test_HIGH_PREPROC_NO_FE_with_signatures.csv\\n\"\n",
    "        f\"  SIG2: train_fit_with_signatures.csv + train_thresh_with_signatures.csv + test_with_signatures.csv\\n\"\n",
    "        f\"  HIGH: train_fit_HIGH_PREPROC_NO_FE.csv + train_thresh_HIGH_PREPROC_NO_FE.csv + test_HIGH_PREPROC_NO_FE.csv\\n\"\n",
    "        f\"  LOW : train_fit_LOW_PREPROC_NO_FE.csv  + train_thresh_LOW_PREPROC_NO_FE.csv  + test_LOW_PREPROC_NO_FE.csv\\n\"\n",
    "        f\"  RAW : train_fit.csv + train_thresh.csv + test.csv\\n\"\n",
    "        f\"Existing CSV files in MODE_DIR:\\n  {existing}\"\n",
    "    )\n",
    "\n",
    "TRAIN_FIT_PATH, TRAIN_THRESH_PATH, TEST_PATH = resolve_dataset_paths(MODE_DIR)\n",
    "\n",
    "# =========================\n",
    "# Prediction / model output dirs\n",
    "# =========================\n",
    "PRED_ROOT = DATA_DIR.parent / \"4_Evaluation\" / \"Predictions\" / RUN_NAME\n",
    "MODEL_DIR = PRED_ROOT / \"models\"\n",
    "PRED_DIR_THRESH_WORK = PRED_ROOT / \"pred_psv_TRAIN_THRESH_WORK\"\n",
    "PRED_DIR_TEST_WORK   = PRED_ROOT / \"pred_psv_TEST_WORK\"\n",
    "\n",
    "for d in [MODEL_DIR, PRED_DIR_THRESH_WORK, PRED_DIR_TEST_WORK]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"MODE_DIR:\", MODE_DIR)\n",
    "print(\"TRAIN_FIT:\", TRAIN_FIT_PATH)\n",
    "print(\"TRAIN_THRESH:\", TRAIN_THRESH_PATH)\n",
    "print(\"TEST:\", TEST_PATH)\n",
    "print(\"PRED_ROOT:\", PRED_ROOT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_fit shape: (1180166, 78)\n",
      "train_thresh shape: (61120, 78)\n",
      "test shape: (310924, 78)\n",
      "n_features: 76\n",
      "First 15 features: ['Hour', 'HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2', 'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2']\n"
     ]
    }
   ],
   "source": [
    "def load_preproc_csv(path: Path) -> pd.DataFrame:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(path)\n",
    "    df = pd.read_csv(path)\n",
    "    # drop accidental index cols\n",
    "    df = df.loc[:, ~df.columns.str.contains(r\"^Unnamed\")]\n",
    "    return df\n",
    "\n",
    "train_fit = load_preproc_csv(TRAIN_FIT_PATH)\n",
    "train_thresh = load_preproc_csv(TRAIN_THRESH_PATH)   # keep for threshold evaluation later\n",
    "test_df = load_preproc_csv(TEST_PATH)\n",
    "\n",
    "# basic checks\n",
    "for df_name, df in [(\"train_fit\", train_fit), (\"train_thresh\", train_thresh), (\"test\", test_df)]:\n",
    "    for c in [PATIENT_COL, TIME_COL]:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"{df_name} missing required column: {c}\")\n",
    "\n",
    "if LABEL_COL not in train_fit.columns:\n",
    "    raise ValueError(\"train_fit must contain SepsisLabel\")\n",
    "\n",
    "# v1-style sort (only use columns that exist)\n",
    "sort_cols = [c for c in [PATIENT_COL, \"ICULOS\", \"Hour\"] if c in train_fit.columns]\n",
    "train_fit = train_fit.sort_values(sort_cols).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# v1 feature definition:\n",
    "#   drop ONLY Patient_ID and SepsisLabel\n",
    "#   KEEP ICULOS / Hour if they exist\n",
    "# -----------------------------\n",
    "drop_cols = {PATIENT_COL, LABEL_COL}\n",
    "feature_cols = [c for c in train_fit.columns if c not in drop_cols]\n",
    "\n",
    "print(\"train_fit shape:\", train_fit.shape)\n",
    "print(\"train_thresh shape:\", train_thresh.shape)\n",
    "print(\"test shape:\", test_df.shape)\n",
    "print(\"n_features:\", len(feature_cols))\n",
    "print(\"First 15 features:\", feature_cols[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17004, number of negative: 927794\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.129026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11530\n",
      "[LightGBM] [Info] Number of data points in the train set: 944798, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.017997 -> initscore=-3.999361\n",
      "[LightGBM] [Info] Start training from score -3.999361\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.825569\n",
      "[200]\tvalid_0's auc: 0.827437\n",
      "[300]\tvalid_0's auc: 0.826072\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's auc: 0.827729\n",
      "Fold 1: best_iter=177  pos=17004 neg=927794 spw=54.56  AUROC=0.8277  AUPRC=0.0944\n",
      "[LightGBM] [Info] Number of positive: 16985, number of negative: 927378\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11709\n",
      "[LightGBM] [Info] Number of data points in the train set: 944363, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.017986 -> initscore=-4.000031\n",
      "[LightGBM] [Info] Start training from score -4.000031\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.843664\n",
      "[200]\tvalid_0's auc: 0.844901\n",
      "[300]\tvalid_0's auc: 0.841701\n",
      "[400]\tvalid_0's auc: 0.838887\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's auc: 0.844901\n",
      "Fold 2: best_iter=200  pos=16985 neg=927378 spw=54.60  AUROC=0.8449  AUPRC=0.1172\n",
      "[LightGBM] [Info] Number of positive: 17000, number of negative: 926740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11614\n",
      "[LightGBM] [Info] Number of data points in the train set: 943740, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018013 -> initscore=-3.998460\n",
      "[LightGBM] [Info] Start training from score -3.998460\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.836147\n",
      "[200]\tvalid_0's auc: 0.839267\n",
      "[300]\tvalid_0's auc: 0.837933\n",
      "[400]\tvalid_0's auc: 0.834645\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's auc: 0.839502\n",
      "Fold 3: best_iter=221  pos=17000 neg=926740 spw=54.51  AUROC=0.8395  AUPRC=0.1146\n",
      "[LightGBM] [Info] Number of positive: 16988, number of negative: 925607\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.106255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11400\n",
      "[LightGBM] [Info] Number of data points in the train set: 942595, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018023 -> initscore=-3.997943\n",
      "[LightGBM] [Info] Start training from score -3.997943\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.836785\n",
      "[200]\tvalid_0's auc: 0.835052\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.83702\n",
      "Fold 4: best_iter=94  pos=16988 neg=925607 spw=54.49  AUROC=0.8370  AUPRC=0.1175\n",
      "[LightGBM] [Info] Number of positive: 17011, number of negative: 928157\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.116750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11339\n",
      "[LightGBM] [Info] Number of data points in the train set: 945168, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.017998 -> initscore=-3.999341\n",
      "[LightGBM] [Info] Start training from score -3.999341\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.83833\n",
      "[200]\tvalid_0's auc: 0.83786\n",
      "[300]\tvalid_0's auc: 0.833371\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's auc: 0.839066\n",
      "Fold 5: best_iter=164  pos=17011 neg=928157 spw=54.56  AUROC=0.8391  AUPRC=0.1142\n",
      "\n",
      "Fold best_iterations: [177, 200, 221, 94, 164]\n",
      "Mean AUROC=0.8376 \u00b1 0.0056\n",
      "Mean AUPRC=0.1116 \u00b1 0.0087\n"
     ]
    }
   ],
   "source": [
    "# patient-level stratification label (v1): patient ever septic\n",
    "patient_y = train_fit.groupby(PATIENT_COL)[LABEL_COL].max().astype(int)\n",
    "patient_ids = patient_y.index.to_numpy()\n",
    "patient_labels = patient_y.values\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_iters = []\n",
    "fold_metrics = []  # (auroc, auprc)\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(patient_ids, patient_labels), 1):\n",
    "    tr_pids = set(patient_ids[tr_idx])\n",
    "    va_pids = set(patient_ids[va_idx])\n",
    "\n",
    "    tr = train_fit[train_fit[PATIENT_COL].isin(tr_pids)]\n",
    "    va = train_fit[train_fit[PATIENT_COL].isin(va_pids)]\n",
    "\n",
    "    X_tr = tr[feature_cols]\n",
    "    y_tr = tr[LABEL_COL].astype(int).to_numpy()\n",
    "\n",
    "    X_va = va[feature_cols]\n",
    "    y_va = va[LABEL_COL].astype(int).to_numpy()\n",
    "\n",
    "    # v1-style fold scale_pos_weight (row-level)\n",
    "    pos = int((y_tr == 1).sum())\n",
    "    neg = int((y_tr == 0).sum())\n",
    "    spw = neg / max(pos, 1)\n",
    "\n",
    "    model = lgb.LGBMClassifier(\n",
    "        objective=\"binary\",\n",
    "        metric=\"auc\",\n",
    "        n_estimators=4000,\n",
    "        learning_rate=0.03,\n",
    "        num_leaves=64,\n",
    "        min_child_samples=50,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        scale_pos_weight=spw,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[lgb.early_stopping(200), lgb.log_evaluation(100)]\n",
    "    )\n",
    "\n",
    "    bi = int(model.best_iteration_ or model.n_estimators_)\n",
    "    best_iters.append(bi)\n",
    "\n",
    "    p_va = model.predict_proba(X_va)[:, 1]\n",
    "    auroc = roc_auc_score(y_va, p_va)\n",
    "    auprc = average_precision_score(y_va, p_va)\n",
    "    fold_metrics.append((auroc, auprc))\n",
    "\n",
    "    print(f\"Fold {fold}: best_iter={bi}  pos={pos} neg={neg} spw={spw:.2f}  AUROC={auroc:.4f}  AUPRC={auprc:.4f}\")\n",
    "\n",
    "best_iters = np.array(best_iters, dtype=int)\n",
    "m = np.array(fold_metrics)\n",
    "\n",
    "print(\"\\nFold best_iterations:\", best_iters.tolist())\n",
    "print(f\"Mean AUROC={m[:,0].mean():.4f} \u00b1 {m[:,0].std():.4f}\")\n",
    "print(f\"Mean AUPRC={m[:,1].mean():.4f} \u00b1 {m[:,1].std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto BEST_N (median of folds): 177\n",
      "[LightGBM] [Info] Number of positive: 21247, number of negative: 1158919\n",
      "[LightGBM] [Info] Total Bins 11541\n",
      "[LightGBM] [Info] Number of data points in the train set: 1180166, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018003 -> initscore=-3.999027\n",
      "[LightGBM] [Info] Start training from score -3.999027\n",
      "Trained final model.\n",
      "Full train pos: 21247 neg: 1158919 scale_pos_weight: 54.54506518567327\n",
      "Final model trees: 177\n"
     ]
    }
   ],
   "source": [
    "# Robust automatic final #trees: median of fold best_iterations\n",
    "BEST_N = int(np.median(best_iters))\n",
    "print(\"Auto BEST_N (median of folds):\", BEST_N)\n",
    "\n",
    "X_full = train_fit[feature_cols]\n",
    "y_full = train_fit[LABEL_COL].astype(int).to_numpy()\n",
    "\n",
    "# v1-style full-data scale_pos_weight\n",
    "pos = int((y_full == 1).sum())\n",
    "neg = int((y_full == 0).sum())\n",
    "scale_pos_weight = neg / max(pos, 1)\n",
    "\n",
    "final_model = lgb.LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    metric=\"auc\",\n",
    "    n_estimators=BEST_N,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    min_child_samples=50,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    force_row_wise=True,\n",
    ")\n",
    "\n",
    "final_model.fit(X_full, y_full)\n",
    "\n",
    "# IMPORTANT: keep name `booster` for your existing v2 prediction-writing cell\n",
    "booster = final_model.booster_\n",
    "\n",
    "print(\"Trained final model.\")\n",
    "print(\"Full train pos:\", pos, \"neg:\", neg, \"scale_pos_weight:\", scale_pos_weight)\n",
    "print(\"Final model trees:\", BEST_N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: /teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/LIGHTGBM_HighPreproc_NoFe/models/lgbm_model_High_Preproc_NoFe_CSV_BESTN_177.txt\n",
      "Saved features: /teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/LIGHTGBM_HighPreproc_NoFe/models/lgbm_feature_names_High_Preproc_NoFe_CSV_BESTN_177.txt\n"
     ]
    }
   ],
   "source": [
    "MODE_TAG = MODE_DIR.name\n",
    "\n",
    "MODEL_PATH = MODEL_DIR / f\"lgbm_model_{MODE_TAG}_BESTN_{BEST_N}.txt\"\n",
    "FEATURES_PATH = MODEL_DIR / f\"lgbm_feature_names_{MODE_TAG}_BESTN_{BEST_N}.txt\"\n",
    "\n",
    "booster.save_model(str(MODEL_PATH), num_iteration=BEST_N)\n",
    "\n",
    "with open(FEATURES_PATH, \"w\") as f:\n",
    "    for c in feature_cols:\n",
    "        f.write(c + \"\\n\")\n",
    "\n",
    "print(\"Saved model:\", MODEL_PATH)\n",
    "print(\"Saved features:\", FEATURES_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1614 PSV files -> /teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/LIGHTGBM_HighPreproc_NoFe/pred_psv_TRAIN_THRESH_WORK\n",
      "Wrote 8068 PSV files -> /teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/LIGHTGBM_HighPreproc_NoFe/pred_psv_TEST_WORK\n"
     ]
    }
   ],
   "source": [
    "def ensure_empty_dir(dir_path: Path):\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    for f in dir_path.glob(\"*.psv\"):\n",
    "        f.unlink()\n",
    "\n",
    "def write_prob_file(out_path: Path, prob: np.ndarray):\n",
    "    pd.DataFrame({\"PredictedProbability\": prob.astype(float)}).to_csv(out_path, sep=\"|\", index=False)\n",
    "\n",
    "def write_psv_predictions_from_preproc_csv(df: pd.DataFrame, out_dir: Path, booster: lgb.Booster):\n",
    "    ensure_empty_dir(out_dir)\n",
    "\n",
    "    df = df.drop(columns=[LABEL_COL], errors=\"ignore\")\n",
    "    df = df.sort_values([PATIENT_COL, TIME_COL]).reset_index(drop=True)\n",
    "\n",
    "    model_features = booster.feature_name()\n",
    "    missing = [c for c in model_features if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing {len(missing)} model features in inference df. Example: {missing[:10]}\")\n",
    "\n",
    "    n_files = 0\n",
    "    for pid, g in df.groupby(PATIENT_COL, sort=False):\n",
    "        g = g.sort_values(TIME_COL)\n",
    "        X = g[model_features]\n",
    "        prob = booster.predict(X, num_iteration=BEST_N)\n",
    "\n",
    "        out_path = out_dir / f\"p{int(pid):06d}.psv\"\n",
    "        write_prob_file(out_path, prob)\n",
    "        n_files += 1\n",
    "\n",
    "    print(f\"Wrote {n_files} PSV files -> {out_dir}\")\n",
    "\n",
    "# Train_thresh predictions (for threshold sweep)\n",
    "write_psv_predictions_from_preproc_csv(train_thresh, PRED_DIR_THRESH_WORK, booster)\n",
    "\n",
    "# Test predictions\n",
    "write_psv_predictions_from_preproc_csv(test_df, PRED_DIR_TEST_WORK, booster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_NAME: LIGHTGBM_HighPreproc_NoFe\n",
      "Model: lgbm_model_High_Preproc_NoFe_CSV_BESTN_177.txt\n",
      "Features: lgbm_feature_names_High_Preproc_NoFe_CSV_BESTN_177.txt\n",
      "Thresh work: /teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/LIGHTGBM_HighPreproc_NoFe/pred_psv_TRAIN_THRESH_WORK\n",
      "Test work: /teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/LIGHTGBM_HighPreproc_NoFe/pred_psv_TEST_WORK\n",
      "\n",
      "Next: run Threshold_Sweep_And_Official_Eval.ipynb\n",
      "Point it to these WORK folders to compute official utility + final thresholded folders.\n"
     ]
    }
   ],
   "source": [
    "print(\"RUN_NAME:\", RUN_NAME)\n",
    "print(\"Model:\", MODEL_PATH.name)\n",
    "print(\"Features:\", FEATURES_PATH.name)\n",
    "print(\"Thresh work:\", PRED_DIR_THRESH_WORK)\n",
    "print(\"Test work:\", PRED_DIR_TEST_WORK)\n",
    "\n",
    "print(\"\\nNext: run Threshold_Sweep_And_Official_Eval.ipynb\")\n",
    "print(\"Point it to these WORK folders to compute official utility + final thresholded folders.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}