{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "66766189",
      "metadata": {},
      "source": [
        "# qSOFA Proxy Workbook (No ML)\n",
        "\n",
        "This notebook computes a **qSOFA approximation** on your preprocessed sepsis dataset and exports the result in the **same folder/workflow layout** you used in *LIGHTGBMv2* — but **without** training any model.\n",
        "\n",
        "Because your dataset does **not** include GCS, we use a **2-item qSOFA proxy**:\n",
        "\n",
        "- Respiratory rate **Resp ≥ 22**\n",
        "- Systolic blood pressure **SBP ≤ 100**\n",
        "\n",
        "We compute:\n",
        "\n",
        "- `qSOFA_score_2` in {0,1,2}\n",
        "- `qSOFA_Label` = 1 iff `qSOFA_score_2 ≥ 2` (i.e., **both** criteria are met)\n",
        "\n",
        "Finally, we export **per-patient `.psv` files** with a `PredictedProbability` column so you can reuse your existing evaluation notebook to compute the official **utility score**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5872f05b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODE_DIR: /teamspace/studios/this_studio/detecting_Sepsis/data/High_Preproc_NoFe_CSV\n",
            "TRAIN_FIT: /teamspace/studios/this_studio/detecting_Sepsis/data/High_Preproc_NoFe_CSV/train_fit_HIGH_PREPROC_NO_FE.csv\n",
            "TRAIN_THRESH: /teamspace/studios/this_studio/detecting_Sepsis/data/High_Preproc_NoFe_CSV/train_thresh_HIGH_PREPROC_NO_FE.csv\n",
            "TEST: /teamspace/studios/this_studio/detecting_Sepsis/data/High_Preproc_NoFe_CSV/test_HIGH_PREPROC_NO_FE.csv\n",
            "PRED_ROOT: /teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/qSOFA_PROXY_HighPreproc_NoFe\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# =========================\n",
        "# Set ONCE (same pattern as LIGHTGBMv2)\n",
        "# =========================\n",
        "DATA_DIR = Path(\"/teamspace/studios/this_studio/detecting_Sepsis/data\")\n",
        "\n",
        "# Point directly to the dataset variant you want to use:\n",
        "MODE_DIR = DATA_DIR / \"High_Preproc_NoFe_CSV\"\n",
        "#MODE_DIR = DATA_DIR / \"Low_Preproc_NoFe_CSV\"\n",
        "#MODE_DIR = DATA_DIR / \"raw_CSV\"\n",
        "\n",
        "# One run folder name (used under 4_Evaluation/Predictions/)\n",
        "RUN_NAME = \"qSOFA_PROXY_HighPreproc_NoFe\"   # change once per experiment\n",
        "\n",
        "# =========================\n",
        "# Conventions\n",
        "# =========================\n",
        "PATIENT_COL = \"Patient_ID\"\n",
        "TIME_COL    = \"ICULOS\"\n",
        "LABEL_COL   = \"SepsisLabel\"  # original label (kept for reference)\n",
        "\n",
        "# =========================\n",
        "# Resolve dataset files from MODE_DIR (AUTO)\n",
        "# =========================\n",
        "def resolve_dataset_paths(mode_dir: Path):\n",
        "    if not mode_dir.exists():\n",
        "        raise FileNotFoundError(f\"MODE_DIR does not exist: {mode_dir}\")\n",
        "\n",
        "    candidates = [\n",
        "        # HIGH\n",
        "        (\"train_fit_HIGH_PREPROC_NO_FE.csv\",\n",
        "         \"train_thresh_HIGH_PREPROC_NO_FE.csv\",\n",
        "         \"test_HIGH_PREPROC_NO_FE.csv\"),\n",
        "        # LOW\n",
        "        (\"train_fit_LOW_PREPROC_NO_FE.csv\",\n",
        "         \"train_thresh_LOW_PREPROC_NO_FE.csv\",\n",
        "         \"test_LOW_PREPROC_NO_FE.csv\"),\n",
        "        # RAW\n",
        "        (\"train_fit.csv\",\n",
        "         \"train_thresh.csv\",\n",
        "         \"test.csv\"),\n",
        "    ]\n",
        "\n",
        "    for fit, thresh, test in candidates:\n",
        "        p_fit = mode_dir / fit\n",
        "        p_thr = mode_dir / thresh\n",
        "        p_tst = mode_dir / test\n",
        "        if p_fit.exists() and p_thr.exists() and p_tst.exists():\n",
        "            return p_fit, p_thr, p_tst\n",
        "\n",
        "    existing = sorted([p.name for p in mode_dir.glob(\"*.csv\")])\n",
        "    raise FileNotFoundError(\n",
        "        f\"Could not resolve dataset files in MODE_DIR={mode_dir}\\n\"\n",
        "        f\"Expected one of these naming schemes:\\n\"\n",
        "        f\"  HIGH: train_fit_HIGH_PREPROC_NO_FE.csv + train_thresh_HIGH_PREPROC_NO_FE.csv + test_HIGH_PREPROC_NO_FE.csv\\n\"\n",
        "        f\"  LOW : train_fit_LOW_PREPROC_NO_FE.csv  + train_thresh_LOW_PREPROC_NO_FE.csv  + test_LOW_PREPROC_NO_FE.csv\\n\"\n",
        "        f\"  RAW : train_fit.csv + train_thresh.csv + test.csv\\n\"\n",
        "        f\"Existing CSV files in MODE_DIR:\\n  {existing}\"\n",
        "    )\n",
        "\n",
        "TRAIN_FIT_PATH, TRAIN_THRESH_PATH, TEST_PATH = resolve_dataset_paths(MODE_DIR)\n",
        "\n",
        "# =========================\n",
        "# Prediction output dirs (same layout)\n",
        "# =========================\n",
        "PRED_ROOT = DATA_DIR.parent / \"4_Evaluation\" / \"Predictions\" / RUN_NAME\n",
        "PRED_DIR_THRESH_WORK = PRED_ROOT / \"pred_psv_TRAIN_THRESH_WORK\"\n",
        "PRED_DIR_TEST_WORK   = PRED_ROOT / \"pred_psv_TEST_WORK\"\n",
        "\n",
        "for d in [PRED_DIR_THRESH_WORK, PRED_DIR_TEST_WORK]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"MODE_DIR:\", MODE_DIR)\n",
        "print(\"TRAIN_FIT:\", TRAIN_FIT_PATH)\n",
        "print(\"TRAIN_THRESH:\", TRAIN_THRESH_PATH)\n",
        "print(\"TEST:\", TEST_PATH)\n",
        "print(\"PRED_ROOT:\", PRED_ROOT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd953d11",
      "metadata": {},
      "source": [
        "## Load the preprocessed CSVs\n",
        "\n",
        "This follows the same pattern as your v2 notebook:\n",
        "- `train_fit`: typically used for training (we **don’t** train anything here, but it’s useful for sanity checks)\n",
        "- `train_thresh`: the split you used for threshold selection + official utility evaluation\n",
        "- `test`: the official test split (no labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a0675389",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_fit (1180166, 78) patients: 30654\n",
            "train_thresh (61120, 78) patients: 1614\n",
            "test (310924, 78) patients: 8068\n"
          ]
        }
      ],
      "source": [
        "def load_preproc_csv(path: Path) -> pd.DataFrame:\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(path)\n",
        "    df = pd.read_csv(path)\n",
        "    # drop accidental index cols\n",
        "    df = df.loc[:, ~df.columns.str.contains(r\"^Unnamed\")]\n",
        "    return df\n",
        "\n",
        "train_fit = load_preproc_csv(TRAIN_FIT_PATH)\n",
        "train_thresh = load_preproc_csv(TRAIN_THRESH_PATH)\n",
        "test_df = load_preproc_csv(TEST_PATH)\n",
        "\n",
        "# basic checks\n",
        "for df_name, df in [(\"train_fit\", train_fit), (\"train_thresh\", train_thresh), (\"test\", test_df)]:\n",
        "    print(df_name, df.shape, \"patients:\", df[PATIENT_COL].nunique())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f232e11",
      "metadata": {},
      "source": [
        "## Compute the qSOFA proxy\n",
        "\n",
        "Your column names match the PhysioNet convention:\n",
        "\n",
        "- `Resp` for respiratory rate\n",
        "- `SBP` for systolic blood pressure\n",
        "\n",
        "We compute a 2-component qSOFA proxy:\n",
        "\n",
        "- `rr_flag  = 1 if Resp ≥ 22 else 0`\n",
        "- `sbp_flag = 1 if SBP ≤ 100 else 0`\n",
        "\n",
        "Then:\n",
        "\n",
        "- `qSOFA_score_2 = rr_flag + sbp_flag`  (0–2)\n",
        "- `qSOFA_Label = 1 if qSOFA_score_2 ≥ 2 else 0`\n",
        "\n",
        "**NaN behavior:** comparisons with NaN become False, so missing values contribute 0 to the score.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cfc867a2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SBP</th>\n",
              "      <th>Resp</th>\n",
              "      <th>qSOFA_score_2</th>\n",
              "      <th>qSOFA_Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>122.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>122.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>122.0</td>\n",
              "      <td>24.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     SBP  Resp  qSOFA_score_2  qSOFA_Label\n",
              "0    0.0   0.0              1            0\n",
              "1   98.0  19.0              1            0\n",
              "2  122.0  22.0              1            0\n",
              "3  122.0  30.0              1            0\n",
              "4  122.0  24.5              1            0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def add_qsofa_proxy(df: pd.DataFrame, resp_col: str = \"Resp\", sbp_col: str = \"SBP\") -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "\n",
        "    if resp_col not in out.columns:\n",
        "        raise KeyError(f\"Missing expected resp column: {resp_col}\")\n",
        "    if sbp_col not in out.columns:\n",
        "        raise KeyError(f\"Missing expected SBP column: {sbp_col}\")\n",
        "\n",
        "    rr_flag  = (out[resp_col] >= 22).astype(\"int8\")\n",
        "    sbp_flag = (out[sbp_col] <= 100).astype(\"int8\")\n",
        "\n",
        "    out[\"qSOFA_score_2\"] = (rr_flag + sbp_flag).astype(\"int8\")\n",
        "    out[\"qSOFA_Label\"]   = (out[\"qSOFA_score_2\"] >= 2).astype(\"int8\")\n",
        "\n",
        "    # Optional probability-style output:\n",
        "    #  - If you want strict binary predictions: use qSOFA_Label (0/1).\n",
        "    #  - If you want a graded score: use qSOFA_score_2 / 2 (0, 0.5, 1).\n",
        "    out[\"qSOFA_Prob_binary\"] = out[\"qSOFA_Label\"].astype(float)\n",
        "    out[\"qSOFA_Prob_graded\"] = (out[\"qSOFA_score_2\"].astype(float) / 2.0)\n",
        "\n",
        "    return out\n",
        "\n",
        "train_fit_q = add_qsofa_proxy(train_fit)\n",
        "train_thresh_q = add_qsofa_proxy(train_thresh)\n",
        "test_q = add_qsofa_proxy(test_df)\n",
        "\n",
        "train_fit_q[[\"SBP\",\"Resp\",\"qSOFA_score_2\",\"qSOFA_Label\"]].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff1caa34",
      "metadata": {},
      "source": [
        "## Quick sanity checks\n",
        "\n",
        "- Distribution of the proxy label\n",
        "- How often each criterion fires\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "716c4806",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_fit: rows=1,180,166 patients=30,654\n",
            "  RR>=22 rate:  0.236\n",
            "  SBP<=100 rate:0.186\n",
            "  qSOFA_Label=1:0.040\n",
            "\n",
            "train_thresh: rows=61,120 patients=1,614\n",
            "  RR>=22 rate:  0.240\n",
            "  SBP<=100 rate:0.186\n",
            "  qSOFA_Label=1:0.041\n",
            "\n",
            "test: rows=310,924 patients=8,068\n",
            "  RR>=22 rate:  0.241\n",
            "  SBP<=100 rate:0.190\n",
            "  qSOFA_Label=1:0.043\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def describe_qsofa(df: pd.DataFrame, name: str):\n",
        "    rr = (df[\"Resp\"] >= 22).mean()\n",
        "    sbp = (df[\"SBP\"] <= 100).mean()\n",
        "    lbl = df[\"qSOFA_Label\"].mean()\n",
        "    print(f\"{name}: rows={len(df):,} patients={df[PATIENT_COL].nunique():,}\")\n",
        "    print(f\"  RR>=22 rate:  {rr:.3f}\")\n",
        "    print(f\"  SBP<=100 rate:{sbp:.3f}\")\n",
        "    print(f\"  qSOFA_Label=1:{lbl:.3f}\")\n",
        "    print()\n",
        "\n",
        "describe_qsofa(train_fit_q, \"train_fit\")\n",
        "describe_qsofa(train_thresh_q, \"train_thresh\")\n",
        "describe_qsofa(test_q, \"test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cce369b9",
      "metadata": {},
      "source": [
        "## Export per-patient `.psv` files (same evaluation workflow)\n",
        "\n",
        "Your evaluation pipeline expects one `.psv` file per patient, with a `PredictedProbability` column, in folders like:\n",
        "\n",
        "- `.../4_Evaluation/Predictions/<RUN_NAME>/pred_psv_TRAIN_THRESH_WORK/`\n",
        "- `.../4_Evaluation/Predictions/<RUN_NAME>/pred_psv_TEST_WORK/`\n",
        "\n",
        "We write those files using either:\n",
        "\n",
        "- **Binary**: `PredictedProbability = qSOFA_Prob_binary` (0 or 1)\n",
        "- **Graded**: `PredictedProbability = qSOFA_Prob_graded` (0, 0.5, 1)\n",
        "\n",
        "For strict “qSOFA positive” behavior, binary is usually what you want.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1c84d2a7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote:\n",
            "  Thresh work: /teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/qSOFA_PROXY_HighPreproc_NoFe/pred_psv_TRAIN_THRESH_WORK\n",
            "  Test work:   /teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/qSOFA_PROXY_HighPreproc_NoFe/pred_psv_TEST_WORK\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def ensure_empty_dir(dir_path: Path):\n",
        "    dir_path.mkdir(parents=True, exist_ok=True)\n",
        "    for f in dir_path.glob(\"*.psv\"):\n",
        "        f.unlink()\n",
        "\n",
        "def write_prob_file(out_path: Path, prob: np.ndarray):\n",
        "    pd.DataFrame({\"PredictedProbability\": prob.astype(float)}).to_csv(out_path, sep=\"|\", index=False)\n",
        "\n",
        "def format_patient_id(pid) -> str:\n",
        "    \"\"\"Match the PhysioNet-style naming: p000011.psv (zero-padded to 6 digits).\n",
        "\n",
        "    Accepts pid as int/float/str, including values like:\n",
        "      - 11\n",
        "      - \"11\"\n",
        "      - \"p11\"\n",
        "      - \"p000011\"\n",
        "    \"\"\"\n",
        "    s = str(pid)\n",
        "    m = re.search(r\"(\\d+)\", s)\n",
        "    if not m:\n",
        "        # Fallback: use raw string\n",
        "        return s\n",
        "    n = int(m.group(1))\n",
        "    return f\"p{n:06d}\"\n",
        "\n",
        "def write_psv_predictions_from_df(df: pd.DataFrame, out_dir: Path, prob_col: str):\n",
        "    if prob_col not in df.columns:\n",
        "        raise KeyError(f\"Missing prob_col='{prob_col}' in df.columns\")\n",
        "\n",
        "    ensure_empty_dir(out_dir)\n",
        "\n",
        "    # Ensure stable order within patient (by TIME_COL)\n",
        "    df_sorted = df.sort_values([PATIENT_COL, TIME_COL]).reset_index(drop=True)\n",
        "\n",
        "    for pid, g in df_sorted.groupby(PATIENT_COL, sort=False):\n",
        "        prob = g[prob_col].to_numpy()\n",
        "        fname = format_patient_id(pid)\n",
        "        out_path = out_dir / f\"{fname}.psv\"\n",
        "        write_prob_file(out_path, prob)\n",
        "\n",
        "# Choose which probability definition to export:\n",
        "PROB_COL_TO_EXPORT = \"qSOFA_Prob_binary\"   # strict qSOFA-positive rows\n",
        "#PROB_COL_TO_EXPORT = \"qSOFA_Prob_graded\"  # graded {0, 0.5, 1}\n",
        "\n",
        "write_psv_predictions_from_df(train_thresh_q, PRED_DIR_THRESH_WORK, PROB_COL_TO_EXPORT)\n",
        "write_psv_predictions_from_df(test_q, PRED_DIR_TEST_WORK, PROB_COL_TO_EXPORT)\n",
        "\n",
        "print(\"Wrote:\")\n",
        "print(\"  Thresh work:\", PRED_DIR_THRESH_WORK)\n",
        "print(\"  Test work:  \", PRED_DIR_TEST_WORK)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "71d24c5e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote aggressive alarm-policy predictions to:\n",
            "  Thresh work: /teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/qSOFA_aggresive_Alarm_Policy/pred_psv_TRAIN_THRESH_WORK\n",
            "  Test work:   /teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/qSOFA_aggresive_Alarm_Policy/pred_psv_TEST_WORK\n"
          ]
        }
      ],
      "source": [
        "# --- Aggressive alarm policy export (same workflow / folder layout) ---\n",
        "# Policy: once qSOFA triggers at any hour for a patient, all subsequent hours stay positive.\n",
        "\n",
        "POLICY_RUN_NAME = \"qSOFA_aggresive_Alarm_Policy\"  # folder name under 4_Evaluation/Predictions/\n",
        "\n",
        "PRED_ROOT_ALARM = DATA_DIR.parent / \"4_Evaluation\" / \"Predictions\" / POLICY_RUN_NAME\n",
        "PRED_DIR_ALARM_THRESH_WORK = PRED_ROOT_ALARM / \"pred_psv_TRAIN_THRESH_WORK\"\n",
        "PRED_DIR_ALARM_TEST_WORK   = PRED_ROOT_ALARM / \"pred_psv_TEST_WORK\"\n",
        "\n",
        "for d in [PRED_DIR_ALARM_THRESH_WORK, PRED_DIR_ALARM_TEST_WORK]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def add_aggressive_alarm_policy(\n",
        "    df: pd.DataFrame,\n",
        "    base_label_col: str = \"qSOFA_Label\",\n",
        "    patient_col: str = PATIENT_COL,\n",
        "    time_col: str = TIME_COL,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Return df with alarmed label/probability.\n",
        "\n",
        "    - base_label_col is the per-row trigger (0/1).\n",
        "    - Alarm policy: within each patient, cumulative max over time.\n",
        "    \"\"\"\n",
        "    if base_label_col not in df.columns:\n",
        "        raise KeyError(f\"Missing base_label_col='{base_label_col}' in df.columns\")\n",
        "\n",
        "    if patient_col not in df.columns:\n",
        "        raise KeyError(f\"Missing patient_col='{patient_col}' in df.columns\")\n",
        "\n",
        "    # Time col fallback (keeps notebook robust across variants)\n",
        "    if time_col not in df.columns:\n",
        "        time_col = \"Hour\" if \"Hour\" in df.columns else None\n",
        "    if time_col is None:\n",
        "        raise KeyError(f\"Missing time column: expected '{TIME_COL}' or 'Hour'\")\n",
        "\n",
        "    out = df.sort_values([patient_col, time_col]).copy()\n",
        "\n",
        "    out[\"qSOFA_AlarmLabel\"] = (\n",
        "        out.groupby(patient_col)[base_label_col]\n",
        "           .transform(lambda s: s.fillna(0).astype(int).cummax())\n",
        "           .astype(\"int8\")\n",
        "    )\n",
        "    out[\"qSOFA_AlarmProb\"] = out[\"qSOFA_AlarmLabel\"].astype(\"float32\")\n",
        "    return out\n",
        "\n",
        "# Apply policy to the same splits you already export for utility evaluation\n",
        "train_thresh_alarm = add_aggressive_alarm_policy(train_thresh_q)\n",
        "test_alarm         = add_aggressive_alarm_policy(test_q)\n",
        "\n",
        "# Export with the same PSV conventions (one file per patient, p000000.psv naming)\n",
        "write_psv_predictions_from_df(train_thresh_alarm, PRED_DIR_ALARM_THRESH_WORK, prob_col=\"qSOFA_AlarmProb\")\n",
        "write_psv_predictions_from_df(test_alarm,         PRED_DIR_ALARM_TEST_WORK,   prob_col=\"qSOFA_AlarmProb\")\n",
        "\n",
        "print(\"Wrote aggressive alarm-policy predictions to:\")\n",
        "print(\"  Thresh work:\", PRED_DIR_ALARM_THRESH_WORK)\n",
        "print(\"  Test work:  \", PRED_DIR_ALARM_TEST_WORK)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8093d6d",
      "metadata": {},
      "source": [
        "## Next step: compute utility with your existing evaluation notebook\n",
        "\n",
        "You can now run your existing `Threshold_Sweep_And_Official_Eval.ipynb` and point it to:\n",
        "\n",
        "- `PRED_DIR_THRESH_WORK` (for threshold selection + utility on the threshold split)\n",
        "- `PRED_DIR_TEST_WORK` (for final evaluation/export)\n",
        "\n",
        "Notes:\n",
        "- If you exported **binary** probabilities (0/1), threshold sweeps will mostly behave like a fixed classifier.\n",
        "- If you exported **graded** probabilities (0/0.5/1), you’ll get a more meaningful threshold sweep curve.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "70b84fd9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RUN_NAME: qSOFA_PROXY_HighPreproc_NoFe\n",
            "Thresh work folder: /teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/qSOFA_PROXY_HighPreproc_NoFe/pred_psv_TRAIN_THRESH_WORK\n",
            "Test work folder:   /teamspace/studios/this_studio/detecting_Sepsis/4_Evaluation/Predictions/qSOFA_PROXY_HighPreproc_NoFe/pred_psv_TEST_WORK\n",
            "Exported prob col:  qSOFA_Prob_binary\n"
          ]
        }
      ],
      "source": [
        "print(\"RUN_NAME:\", RUN_NAME)\n",
        "print(\"Thresh work folder:\", PRED_DIR_THRESH_WORK)\n",
        "print(\"Test work folder:  \", PRED_DIR_TEST_WORK)\n",
        "print(\"Exported prob col: \", PROB_COL_TO_EXPORT)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
